## 数据结构
> HashMap的存储结构是数组+链表+红黑树

## 并发
1. HashMap非线程安全
2. 并发环境下可能出现扩容导致的死链问题
3. 如果需要并发环境下使用可以考虑ConcurrentHashMap或HashTable

## 效率
1. HashMap中使用了数组+链表+红黑树来保证效率
2. 当bucket上链表的节点数达到8时，会将链表转换为红黑树
3. 当bucket上的红黑树节点数小于6时，会将红黑树转换为链表

## 重要属性
1. table：默认为null，第一次插入数据时初始化默认大小为16，存储Node节点的数据，每次扩容总会时2的幂次方
2. threshold：阀值，当节点数大于此值时扩容table，默认为容量×0.75
3. loadFactor：加载因子，用于扩容的阀值计算，默认0.75


## 重要内部类
1. Node：存储链表节点的数据结构
2. TreeNode：存储红黑树节点的数据结构


## 重要方法

1. put方法
	- 1.1. 计算key的hash值，如果key为null则hash值为0
	- 1.2. 如果table还没有初始化，则调用扩容方法resize初始化table，大小默认为16
	- 1.3. 根据计算出的hash值找到table中的bucket
	- 1.4. 如果当前bucket为空，则直接插入一个新的Node节点
	- 1.5. 如果头结点的hash值相同且key的值相同，则直接替换当前节点的value并返回原始值
	- 1.6. 如果当前节点时红黑树类型，则调用putTreeVal方法插入数据
	- 1.7. 如果当前节点时链表，则遍历当前链表找到hash相等且key值相同的节点直接更新value，如果链表遍历到结尾没有找到相同key的节点，则直接在链表的尾部插入新的Node节点并检查当前链表节点数达到8个时将链表转换为红黑树
	- 1.8. 检查当前table中节点个数达到阀值时调用resize方法扩容
    
2. resize方法
	- 2.1. 如果table还没有初始化，则初始化table，大小默认16
	- 2.2. 初始化一个新的newTab，大小是原table的两倍，并重新计算阀值
	- 2.3. 遍历原来的table，重排每个bucket从新table的尾部开始插入
		- 2.3.1. 如果当前bucket中只有头节点（未发生过碰撞）或是null，则计算hash插入新table的对应位置
		- 2.3.2. 如果当前bucket中是红黑树，则调用红黑树的split方法重排节点
		- 2.3.3. 如果当前bucket中是链表，将链表移入新table
    
    

## jdk1.7与1.8之间的不同
1. 同步机制：
	- 1.7：分段锁，每个segment继承ReentrantLock
	- 1.8：CAS+synchronize保证并发更新
2. 存储结构：
	- 1.7：数组+链表
	- 1.8：数组+链表+红黑树
3. put操作：
	- 1.7：多个线程同时竞争同一个segment锁，获取成功的线程更新map；失败的线程尝试多次获取锁仍未成功，则挂起线程，等待释放锁；
	- 1.8：访问相应的bucket时用synchronize关键字，防止多个线程同时操作同一个bucket，如果该节点的hash不小于0，则遍历链表更新节点或插入新节点；如果该节点时4. treeBin，则通过putTreeVal方法插入节点；更新节点数量并检查链表红黑树转换与扩容；
5. size实现：
	- 1.7：统计每个Segment对象中的元素个数，然后进行累加，但是这种方式计算出来的结果并不一样的准确的。先采用不加锁的方式，连续计算元素的个数，最多计算3次：如果前后两次计算结果相同，则说明计算出来的元素个数是准确的；如果前后两次计算结果都不同，则给每个Segment进行加锁，再计算一次元素的个数；
	- 1.8：通过累加baseCounter与CounterCell数组中的数量，即可得到元素总个数；




## ConcurrentHashMap能完全代替HashTable吗？
> hashTablb的迭代器时强一致性的，而ConcurrentHashMap的迭代器时弱一致性的
